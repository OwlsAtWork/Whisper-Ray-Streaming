# apiVersion: v1
# data:
#   token: <data>
# kind: Secret
# metadata:
#   name: hf-token
#   namespace: app
# type: Opaque

---
apiVersion: ray.io/v1
kind: RayService
metadata:
  name: whisper-streaming
  namespace: app
spec:
  deploymentUnhealthySecondThreshold: 2000
  serviceUnhealthySecondThreshold: 2000  
  rayClusterConfig:
    enableInTreeAutoscaling: true
    headGroupSpec:
      rayStartParams:
        dashboard-host: 0.0.0.0
      template:
        spec:
          containers:
            - env:
                - name: RAY_GRAFANA_HOST
                  value: http://kube-prometheus-stack-grafana.kube-prometheus-stack.svc:80
                - name: RAY_PROMETHEUS_HOST
                  value: http://kube-prometheus-stack-prometheus.kube-prometheus-stack.svc:9090
                - name: PYANNOTE_AUTH_TOKEN
                  valueFrom:
                    secretKeyRef:
                      name: hf-token
                      key: token
                - name: PYTHONFAULTHANDLER
                  value: "1"
              image: 626635410672.dkr.ecr.us-east-1.amazonaws.com/whisper-ray-service:v1
              imagePullPolicy: Always
              name: ray-head
              
              ports:
                - containerPort: 6379
                  name: gcs
                  protocol: TCP
                - containerPort: 8265
                  name: dashboard
                  protocol: TCP
                - containerPort: 10001
                  name: client
                  protocol: TCP
                - containerPort: 8000
                  name: serve
                  protocol: TCP
              resources:
                limits:
                  cpu: "3"
                  memory: 10G
                requests:
                  cpu: "3"
                  memory: 8G
              securityContext:
                capabilities:
                  add:
                    - SYS_PTRACE
              volumeMounts:
                - mountPath: /tmp/ray
                  name: ray-logs
                - mountPath: /var/coredumps
                  name: core-dump-volume
          volumes:
            - name: core-dump-volume
              emptyDir: {}
            - name: ray-logs
              emptyDir: {}
          nodeSelector:
            node-pool: rayservice-head              
          tolerations:
            - key: "ray.io/node-type"
              operator: "Equal"
              value: "head"
              effect: "NoSchedule"              
    rayVersion: 2.9.2
    workerGroupSpecs:
      - groupName: gpu-group
        maxReplicas: 20
        minReplicas: 1
        rayStartParams: {}
        replicas: 2
        template:
          spec:
            containers:
              - env:
                  - name: PYANNOTE_AUTH_TOKEN
                    valueFrom:
                      secretKeyRef:
                        name: hf-token
                        key: token
                  - name: PYTHONFAULTHANDLER
                    value: "1"
                image: 626635410672.dkr.ecr.us-east-1.amazonaws.com/whisper-ray-service:v1
                imagePullPolicy: Always
                name: ray-worker
                resources:
                  limits:
                    cpu: 4
                    memory: 16G
                    nvidia.com/gpu: 1
                  requests:
                    cpu: 3
                    memory: 12G
                    nvidia.com/gpu: 1
                securityContext:
                  capabilities:
                    add:
                      - SYS_PTRACE
                volumeMounts:
                  - mountPath: /var/coredumps
                    name: core-dump-volume
            volumes:
              - name: core-dump-volume
                emptyDir: {}
            nodeSelector:
              node-pool: rayservice-worker               
            tolerations:
              - effect: NoSchedule
                key: ray.io/node-type
                operator: Equal
                value: worker
  serveConfigV2: |
    applications:
      - name: default
        import_path: src.voice_stream_ai_server:entrypoint
        runtime_env:
          working_dir: "https://jarvis-whisper.s3.us-east-1.amazonaws.com/317de3ef07bdc634d40f46967f1008dd9d3c83a004c11aa91d41a0452b9dca56.zip"
        deployments:
        - name: TranscriptionServer
          max_concurrent_queries: 100
          autoscaling_config:
            target_num_ongoing_requests_per_replica: 5
            min_replicas: 1
            max_replicas: 20
            initial_replicas: 1
        - name: FasterWhisperASR
          max_concurrent_queries: 10
          ray_actor_options:
            resources: {"memory": 32_000_000_000}
          autoscaling_config:
            target_num_ongoing_requests_per_replica: 2
            min_replicas: 1
            max_replicas: 20
            initial_replicas: 1
        - name: SileroVAD
          max_concurrent_queries: 5
          autoscaling_config:
            target_num_ongoing_requests_per_replica: 3
            min_replicas: 1
            max_replicas: 20
            initial_replicas: 1